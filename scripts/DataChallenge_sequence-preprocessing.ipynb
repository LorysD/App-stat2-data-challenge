{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6dfdd8",
   "metadata": {},
   "source": [
    "# Pre-processing sequences\n",
    "\n",
    "In this notebook we illustrate how to use utility functions implemented in the **utils.py** file to pre-process the sequences.\n",
    "\n",
    "These functions allow to transform a list of sequences (that are available in the **datachallenge-traindata.csv** file into matrices that can be used by machine-/deep-learning algorithms.\n",
    "More precisely, three types of matrices can be built:\n",
    "* one-hot encoding matrices, as already seen in the TP8 (exercice about CNNs and one-hot encoding) \n",
    "* matrices of kmers tokens, as already seen in TP8 (exercice and CNNs and embeddings)\n",
    "* matrices of kmers profiles, which is equivalent to the well known \"bag of words\" representation in text analysis.\n",
    "\n",
    "You can refer to the last course and to the TP8 for more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8bbbaf",
   "metadata": {},
   "source": [
    "## We first import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1721871",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f35b61-9701-4c8f-af3f-c88282ad1267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generic imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# seaborn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# utility functions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6119c057-10d8-49a3-ba15-7015b8dbb4e1",
   "metadata": {},
   "source": [
    "## 1. Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0b8b9-0225-40a0-aee8-849d407bd5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../dataset/datachallenge-traindata.csv\"\n",
    "df_train = pd.read_csv(train_file, sep = ';')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec4409",
   "metadata": {},
   "source": [
    "### Extract sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6420e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sequences\n",
    "seqs = df_train[\"seq\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479042b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print minimum and maximum sequence length\n",
    "seq_len = [len(x) for x in seqs]\n",
    "print(\"minimum / maximum sequence length = {} / {}\".format(np.min(seq_len),np.max(seq_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show histogram\n",
    "sns.histplot(x=seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28c758b",
   "metadata": {},
   "source": [
    "## 2. Representing sequences using \"one-hot-encoding\" of ATGC bases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7118dd",
   "metadata": {},
   "source": [
    "Note that we can choose to **padd** short sequences to reach the maximum sequence length, or **truncate** long sequences to reach the minimum sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ff99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = utils.build_onehot_matrix(seqs, padd = True, truncate = False)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = utils.build_onehot_matrix(seqs, padd = False, truncate = True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d778766",
   "metadata": {},
   "source": [
    "## 3. Representing sequences as vectors of  kmers tokens / indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b3f567",
   "metadata": {},
   "source": [
    "We first build a dictionary associating an index to each kmer. Note that we will only consider kmers made of A, T, G and C's only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea826a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "kmer_dic = utils.build_kmer_dic(seqs, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63b424",
   "metadata": {},
   "source": [
    "We then extract a matrix containing sequences of kmer indices. Note that here also, we need to choose wheter we want to **padd** short sequences, or **truncate** long sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797bb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = utils.build_kmer_tokens_matrix(seqs, k, kmer_dic, padd = True, truncate = False)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b99cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = utils.build_kmer_tokens_matrix(seqs, k, kmer_dic, padd = False, truncate = True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f176bcc3",
   "metadata": {},
   "source": [
    "We can then check that the values contained in the matrix are comprised between zero and the number of kmers found in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157eb719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"min/max value in X = {}/{} and number of kmers of the dictionary = {}\".format(np.min(X), np.max(X), len(kmer_dic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86acba9-a975-4901-8298-4361be7c8878",
   "metadata": {},
   "source": [
    "## 4. Representing sequences as kmer profiles - vectors counting kmers occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42600a2c",
   "metadata": {},
   "source": [
    "Likewise, we first need to build a dictionary associating an index to each kmer. Note that we will only consider kmers made of A, T, G and C's only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "kmer_dic = utils.build_kmer_dic(seqs, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f10a8",
   "metadata": {},
   "source": [
    "We then extract a matrix containing kmer profiles. Each column of the matrix will correspond to a kmer of the dictionary, and will count the number of occurences of this kmer in the sequences.\n",
    "\n",
    "Note that here we don't need to to padd or truncate sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3fa10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = utils.build_kmer_profile_matrix(seqs, k, kmer_dic)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of columns of X = {} and number of kmers of the dictionary = {}\".format(X.shape[1], len(kmer_dic)))\n",
    "print(\"min/max value in X = {}/{} \".format(np.min(X), np.max(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f32d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
